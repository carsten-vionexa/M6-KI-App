<?xml version="1.0" encoding="UTF-8"?>
<!--This file is auto-generated and is overwritten each time the workflow is saved.
    The metadata have moved to the `workflow-metadata.xml` file.-->
<KNIMEMetaInfo nrOfElements="2" xmlns="http://www.knime.org/2.9/metainfo">
    <element form="multiline" name="Comments" read-only="false"><![CDATA[<p>This workflow demonstrates how to use a local model in KNIME Analytics Platform for sentiment analysis, offering an alternative to traditional lexicon-based methods.</p><p>You can easily download and run the workflow directly in your KNIME installation. For optimal performance, we recommend using the latest version of the KNIME Analytics Platform.</p><p></p><p>Workflow Details</p><p></p><p>This workflow showcases how to use a local model in KNIME Analytics Platform. Refer to the node description of the "<strong>Local GPT4ALL Chat Model Connector</strong>" for more information about setting up a local model on your machine.</p><p></p><p>You <strong>can only run this workflow locally</strong> since its large model size—several GB—makes it unsuitable for uploading to any KNIME Hub.</p><p>Note that the model's processing speed is related to your local machine's capacity. These models are designed to run with a powerful GPU so that performance may be slower on less capable machines.</p><p><strong>Advantages of a Local Model:</strong></p><ul><li><p>No internet connection is needed.</p></li><li><p>There is no risk of data leaks.</p></li></ul><p>Workflow Steps</p><ol><li><p><strong>Model Setup</strong></p><ul><li><p>Set up your local model using the "Local ChatGPT4ALL Chat Model Connector" node description as a reference. You need to download the model to your machine.</p></li></ul></li><li><p><strong>Data Input</strong></p><ul><li><p>E-commerce reviews are used to perform sentiment analysis using the local model.</p></li></ul></li><li><p><strong>Data Sampling</strong></p><ul><li><p>Use the Row Sampling node to sample the data; initially, there were more than 20,000 entries but only 20 rows. This step is crucial for running the workflow on a standard laptop, as processing a large dataset would take a long time.</p></li></ul></li><li><p><strong>Prompt Creation</strong></p><ul><li><p>Create the prompt for the LLM prompter. Example prompt: "Please analyze the sentiment of the following text and respond with either 'positive,' 'negative,' or 'neutral.' Provide only the sentiment label. Here is the review: This shirt is semi-fitted. I like it because it is not boxy but not overly tight. It is not heavy even though it is a sweatshirt material. I wish the neck was a bit higher, but I will wear a tee under it. The back is really cute. It is different, and I like that."</p></li></ul></li><li><p><strong>Processing and Visualization</strong></p><ul><li><p>After the LLM Prompter node finishes processing, the workflows takes the responses, categorize and summarize the reviews based on the sentiment label (negative, neutral, positive), and plot a bar chart by the department with the count of reviews by sentiment label.</p></li></ul></li></ol>

URL: GPT4ALL https://www.nomic.ai/gpt4all
URL: Llama3 LLM Model https://llama.meta.com/llama3/

TAGS: Release 5.3,AI,Generative AI,Llama3]]></element>
    <element form="text" name="Last Edited" read-only="true">2024-07-05 16:08:15 +0200</element>
</KNIMEMetaInfo>