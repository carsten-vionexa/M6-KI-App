<?xml version="1.0" encoding="UTF-8"?>
<workflow-metadata content-type="text/html" xmlns="http://www.knime.org/core/node/workflow/metadata/v1.0">
    <last-modified>2024-07-05T16:08:15.177+02:00</last-modified>
    <description><![CDATA[<p>This workflow demonstrates how to use a local model in KNIME Analytics Platform for sentiment analysis, offering an alternative to traditional lexicon-based methods.</p><p>You can easily download and run the workflow directly in your KNIME installation. For optimal performance, we recommend using the latest version of the KNIME Analytics Platform.</p><p></p><p>Workflow Details</p><p></p><p>This workflow showcases how to use a local model in KNIME Analytics Platform. Refer to the node description of the "<strong>Local GPT4ALL Chat Model Connector</strong>" for more information about setting up a local model on your machine.</p><p></p><p>You <strong>can only run this workflow locally</strong> since its large model size—several GB—makes it unsuitable for uploading to any KNIME Hub.</p><p>Note that the model's processing speed is related to your local machine's capacity. These models are designed to run with a powerful GPU so that performance may be slower on less capable machines.</p><p><strong>Advantages of a Local Model:</strong></p><ul><li><p>No internet connection is needed.</p></li><li><p>There is no risk of data leaks.</p></li></ul><p>Workflow Steps</p><ol><li><p><strong>Model Setup</strong></p><ul><li><p>Set up your local model using the "Local ChatGPT4ALL Chat Model Connector" node description as a reference. You need to download the model to your machine.</p></li></ul></li><li><p><strong>Data Input</strong></p><ul><li><p>E-commerce reviews are used to perform sentiment analysis using the local model.</p></li></ul></li><li><p><strong>Data Sampling</strong></p><ul><li><p>Use the Row Sampling node to sample the data; initially, there were more than 20,000 entries but only 20 rows. This step is crucial for running the workflow on a standard laptop, as processing a large dataset would take a long time.</p></li></ul></li><li><p><strong>Prompt Creation</strong></p><ul><li><p>Create the prompt for the LLM prompter. Example prompt: "Please analyze the sentiment of the following text and respond with either 'positive,' 'negative,' or 'neutral.' Provide only the sentiment label. Here is the review: This shirt is semi-fitted. I like it because it is not boxy but not overly tight. It is not heavy even though it is a sweatshirt material. I wish the neck was a bit higher, but I will wear a tee under it. The back is really cute. It is different, and I like that."</p></li></ul></li><li><p><strong>Processing and Visualization</strong></p><ul><li><p>After the LLM Prompter node finishes processing, the workflows takes the responses, categorize and summarize the reviews based on the sentiment label (negative, neutral, positive), and plot a bar chart by the department with the count of reviews by sentiment label.</p></li></ul></li></ol>]]></description>
    <tags>
        <tag>Release 5.3</tag>
        <tag>AI</tag>
        <tag>Generative AI</tag>
        <tag>Llama3</tag>
    </tags>
    <links>
        <link href="https://www.nomic.ai/gpt4all">GPT4ALL</link>
        <link href="https://llama.meta.com/llama3/">Llama3 LLM Model</link>
    </links>
</workflow-metadata>